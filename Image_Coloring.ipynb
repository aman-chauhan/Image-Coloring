{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image-Coloring.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "vBDR1-WJ7xR1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "AxyP8AK07EZv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Image-Coloring\n",
        "\n",
        "***Reference*** - [Let there be Color!: Joint End-to-end Learning of Global and Local Image Priors for Automatic Image Colorization with Simultaneous Classification - Satoshi Iizuka, Edgar Simo-Serra, Hiroshi Ishikawa](http://hi.cs.waseda.ac.jp/~iizuka/projects/colorization/en/)"
      ]
    },
    {
      "metadata": {
        "id": "Qwtukiv_k_bq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qlJ2JPlFiVni",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Authenticate"
      ]
    },
    {
      "metadata": {
        "id": "d5pG6hlliZ3o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PTBkHnNnidUH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EI2bpZsUe5js",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Upload weights and epochs"
      ]
    },
    {
      "metadata": {
        "id": "BCgi9wNVgpj8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Upload? (1/0)\n",
        "option = 1 #@param\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "prUZsqmrgcG0",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "fa043aff-0f05-4163-b88b-8db7af91a802"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "if option==1:\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for fn in uploaded.keys():\n",
        "        print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c6efc792-1b6a-428a-bae7-30cfc533639a\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c6efc792-1b6a-428a-bae7-30cfc533639a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving epochs.json to epochs.json\n",
            "Saving weights.h5 to weights.h5\n",
            "User uploaded file \"epochs.json\" with length 19320 bytes\n",
            "User uploaded file \"weights.h5\" with length 75987868 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "URcxwckYY2vK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download data from Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "gXjfNKx_Y7kh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "934f3968-1e0b-4aab-d3b7-c5f90e7855d2"
      },
      "cell_type": "code",
      "source": [
        "file_id = '11r-dOQ5Ve2dubFps6D-HTTi7urasqQqn'\n",
        "\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "request = drive_service.files().get_media(fileId=file_id)\n",
        "downloaded = io.BytesIO()\n",
        "downloader = MediaIoBaseDownload(downloaded, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    progress, done = downloader.next_chunk()\n",
        "    print('.',end='')\n",
        "\n",
        "downloaded.seek(0)\n",
        "with open('data.zip','wb') as f:\n",
        "    f.write(downloaded.read())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "......................"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "StIgX6HWqDET",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip -q data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lyDp-PfuvCC-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c024d23a-9b5c-416b-babb-360b9161225e"
      },
      "cell_type": "code",
      "source": [
        "!rm -r __MACOSX\n",
        "!ls epochs.json\n",
        "!rm weights.h5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4\r\n",
            "drwxr-xr-x 1 root root 4096 May 21 17:02 datalab\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vBDR1-WJ7xR1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Library Verification"
      ]
    },
    {
      "metadata": {
        "id": "J3Ir9hbcwrXj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e0f8f212-b278-4cae-a5e2-163b6df0e419"
      },
      "cell_type": "code",
      "source": [
        "!apt-get  -qq install -y graphviz && pip install -q pydot\n",
        "!pip install imageio"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.14.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->imageio) (0.45.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mO6emBpv8Ws1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "metadata": {
        "id": "MSyOVdx_8F0W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67ce3a29-422d-4058-e2be-1bbb51d1fd8e"
      },
      "cell_type": "code",
      "source": [
        "# Keras Libraries\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import UpSampling2D\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Lambda\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers.merge import Add\n",
        "from keras.layers import Input\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils import plot_model\n",
        "from keras.utils import Sequence\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "\n",
        "# Other libraries\n",
        "from skimage.color import rgb2lab\n",
        "from skimage.color import lab2rgb\n",
        "from imageio import imwrite\n",
        "from imageio import imread\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import datetime\n",
        "import json\n",
        "import os"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z6cLDRLNByT1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN Models"
      ]
    },
    {
      "metadata": {
        "id": "PCq5xaItCL2C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Low-Level Feature Network"
      ]
    },
    {
      "metadata": {
        "id": "Bv_cA5xDCK0M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def llfn():\n",
        "    # Input tensor\n",
        "    llfn_input = Input(batch_shape=(None, None, None, 1), name='llfn_input')\n",
        "\n",
        "    # Convolutional Layer with 32 3x3 kernels with double stride and same padding\n",
        "    llfn_conv1 = Conv2D(filters=32, kernel_size=3, strides=2, padding='same', activation='relu',\n",
        "                        kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(llfn_input)\n",
        "    llfn_conv1 = BatchNormalization()(llfn_conv1)\n",
        "\n",
        "    # Convolutional Layer with 64 3x3 kernels with single stride and same padding\n",
        "    llfn_conv2 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu',\n",
        "                        kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(llfn_conv1)\n",
        "    llfn_conv2 = BatchNormalization()(llfn_conv2)\n",
        "\n",
        "    # Convolutional Layer with 64 3x3 kernels with double stride and same padding\n",
        "    llfn_conv3 = Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu',\n",
        "                        kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(llfn_conv2)\n",
        "    llfn_conv3 = BatchNormalization()(llfn_conv3)\n",
        "\n",
        "    # Convolutional Layer with 128 3x3 kernels with single stride and same padding\n",
        "    llfn_conv4 = Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu',\n",
        "                        kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(llfn_conv3)\n",
        "    llfn_conv4 = BatchNormalization()(llfn_conv4)\n",
        "\n",
        "    # Convolutional Layer with 128 3x3 kernels with double stride and same padding\n",
        "    llfn_conv5 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same', activation='relu',\n",
        "                        kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(llfn_conv4)\n",
        "    llfn_conv5 = BatchNormalization()(llfn_conv5)\n",
        "\n",
        "    # Convolutional Layer with 256 3x3 kernels with single stride and same padding\n",
        "    llfn_conv6 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu',\n",
        "                        kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(llfn_conv5)\n",
        "    llfn_conv6 = BatchNormalization()(llfn_conv6)\n",
        "\n",
        "    # Model definition\n",
        "    llfn_model = Model(inputs=llfn_input, outputs=llfn_conv6)\n",
        "\n",
        "    return llfn_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jef__jYXHN4P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Mid-Level Feature Network"
      ]
    },
    {
      "metadata": {
        "id": "g6g5O3g6RWsx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mlfn():\n",
        "    # Input tensor\n",
        "    mlfn_input = Input(batch_shape=(None, None, None, 256), name='mlfn_input')\n",
        "\n",
        "    # Convolutional Layer with 256 3x3 kernels with single stride and same padding\n",
        "    mlfn_conv1 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu',\n",
        "                        kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(mlfn_input)\n",
        "    mlfn_conv1 = BatchNormalization()(mlfn_conv1)\n",
        "\n",
        "    # Convolutional Layer with 256 3x3 kernels with single stride and same padding\n",
        "    mlfn_conv2 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu',\n",
        "                        kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(mlfn_conv1)\n",
        "    mlfn_conv2 = BatchNormalization()(mlfn_conv2)\n",
        "\n",
        "    # Model definition\n",
        "    mlfn_model = Model(inputs=mlfn_input, outputs=mlfn_conv2, name='mlfn_model')\n",
        "\n",
        "    return mlfn_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KQFRK5d6RlZL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Global Feature Network"
      ]
    },
    {
      "metadata": {
        "id": "QsPxihUKReHf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gfn():\n",
        "    # Input tensor\n",
        "    gfn_input = Input(batch_shape=(None, 28, 28, 256), name='gfn_input')\n",
        "\n",
        "    # Convolutional Layer with 256 3x3 kernels with double stride and same padding\n",
        "    gfn_conv1 = Conv2D(filters=256, kernel_size=3, strides=2, padding='same', activation='relu',\n",
        "                       kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(gfn_input)\n",
        "    gfn_conv1 = BatchNormalization()(gfn_conv1)\n",
        "\n",
        "    # Convolutional Layer with 256 3x3 kernels with single stride and same padding\n",
        "    gfn_conv2 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu',\n",
        "                       kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(gfn_conv1)\n",
        "    gfn_conv2 = BatchNormalization()(gfn_conv2)\n",
        "\n",
        "    # Convolutional Layer with 256 3x3 kernels with single stride and same padding\n",
        "    gfn_conv3 = Conv2D(filters=256, kernel_size=3, strides=2, padding='same', activation='relu',\n",
        "                       kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(gfn_conv2)\n",
        "    gfn_conv3 = BatchNormalization()(gfn_conv3)\n",
        "\n",
        "    # Convolutional Layer with 256 3x3 kernels with single stride and same padding\n",
        "    gfn_conv4 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu',\n",
        "                       kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(gfn_conv3)\n",
        "    gfn_conv4 = BatchNormalization()(gfn_conv4)\n",
        "\n",
        "    # Flatten the layer\n",
        "    gfn_flttn = Flatten()(gfn_conv4)\n",
        "\n",
        "    # Fully Connected Layer with 1024 units\n",
        "    gfn_fcon1 = Dense(units=1024, activation='relu', kernel_initializer='he_uniform',\n",
        "                      bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(gfn_flttn)\n",
        "    gfn_fcon1 = BatchNormalization()(gfn_fcon1)\n",
        "    gfn_fcon1 = Dropout(0.20)(gfn_fcon1)\n",
        "\n",
        "    # Fully Connected Layer with 512 units\n",
        "    gfn_fcon2 = Dense(units=512, activation='relu', kernel_initializer='he_uniform',\n",
        "                      bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(gfn_fcon1)\n",
        "    gfn_fcon2 = BatchNormalization()(gfn_fcon2)\n",
        "    gfn_fcon2 = Dropout(0.20)(gfn_fcon2)\n",
        "\n",
        "    # Model definition\n",
        "    gfn_model = Model(inputs=gfn_input, outputs=gfn_fcon2, name='gfn_model')\n",
        "\n",
        "    return gfn_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XQ72nXfARtF8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Classifier Network"
      ]
    },
    {
      "metadata": {
        "id": "-hOvsWsqRveD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clf():\n",
        "    # Input tensor\n",
        "    clf_input = Input(batch_shape=(None, 512), name='clf_input')\n",
        "\n",
        "    # Fully Connected Layer with 256 units\n",
        "    clf_fcon1 = Dense(units=256, activation='relu', kernel_initializer='he_uniform',\n",
        "                      bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(clf_input)\n",
        "    clf_fcon1 = BatchNormalization()(clf_fcon1)\n",
        "    clf_fcon1 = Dropout(0.20)(clf_fcon1)\n",
        "\n",
        "    # Fully Connected Layer with 'output' units\n",
        "    clf_fcon2 = Dense(units=719, activation='softmax', kernel_initializer='he_uniform',\n",
        "                      bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(clf_fcon1)\n",
        "\n",
        "    # Model definition\n",
        "    clf_model = Model(inputs=clf_input, outputs=clf_fcon2, name='clf_model')\n",
        "\n",
        "    return clf_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UjmSn0kdRyYx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Color Network"
      ]
    },
    {
      "metadata": {
        "id": "GaKqz1eDRzsk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def color():\n",
        "    # Input tensor\n",
        "    color_input = Input(batch_shape=(None, None, None, 256), name='color_input')\n",
        "\n",
        "    # Convolutional Layer with 128 3x3 kernels with single stride and same padding\n",
        "    color_conv1 = Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu',\n",
        "                         kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(color_input)\n",
        "    color_conv1 = BatchNormalization()(color_conv1)\n",
        "\n",
        "    # Convolutional Layer with 64 3x3 kernels with single stride and same padding\n",
        "    color_conv2 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu',\n",
        "                         kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(color_conv1)\n",
        "    color_conv2 = BatchNormalization()(color_conv2)\n",
        "\n",
        "    # Upsampling\n",
        "    color_upsm1 = UpSampling2D(size=2)(color_conv2)\n",
        "\n",
        "    # Convolutional Layer with 64 3x3 kernels with single stride and same padding\n",
        "    color_conv3 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu',\n",
        "                         kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(color_upsm1)\n",
        "    color_conv3 = BatchNormalization()(color_conv3)\n",
        "\n",
        "    # Convolutional Layer with 32 3x3 kernels with single stride and same padding\n",
        "    color_conv4 = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu',\n",
        "                         kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(color_conv3)\n",
        "    color_conv4 = BatchNormalization()(color_conv4)\n",
        "\n",
        "    # Upsampling\n",
        "    color_upsm2 = UpSampling2D(size=2)(color_conv4)\n",
        "\n",
        "    # Convolutional Layer with 32 3x3 kernels with single stride and same padding\n",
        "    color_conv5 = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu',\n",
        "                         kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(color_upsm2)\n",
        "    color_conv5 = BatchNormalization()(color_conv5)\n",
        "\n",
        "    # Convolutional Layer with 16 3x3 kernels with single stride and same padding\n",
        "    color_conv6 = Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu',\n",
        "                         kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(color_conv5)\n",
        "    color_conv6 = BatchNormalization()(color_conv6)\n",
        "\n",
        "    # Upsampling\n",
        "    color_upsm3 = UpSampling2D(size=2)(color_conv6)\n",
        "\n",
        "    # Convolutional Layer with 2 3x3 kernels with single stride and same padding\n",
        "    color_conv7 = Conv2D(filters=2, kernel_size=3, strides=1, padding='same',\n",
        "                         activation='sigmoid', kernel_initializer='he_uniform', bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(color_upsm3)\n",
        "\n",
        "    # Model definition\n",
        "    color_model = Model(inputs=color_input, outputs=color_conv7, name='color_model')\n",
        "\n",
        "    return color_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2fl8IgDYTTzn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Full Network"
      ]
    },
    {
      "metadata": {
        "id": "0mh7ip7WTZHf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tile(x, k):\n",
        "    x = K.expand_dims(x, 1)\n",
        "    x = K.expand_dims(x, 1)\n",
        "    x = K.tile(x, [1, k[1], k[2], 1])\n",
        "    return x\n",
        "\n",
        "\n",
        "def model():\n",
        "    color_input = Input(batch_shape=(None, None, None, 1), name='global_color')\n",
        "    color_branch = llfn()(color_input)\n",
        "    color_branch = mlfn()(color_branch)\n",
        "\n",
        "    class_input = Input(batch_shape=(None, 224, 224, 1), name='global_class')\n",
        "    class_branch = llfn()(class_input)\n",
        "    class_branch = gfn()(class_branch)\n",
        "\n",
        "    gfn_units = Dense(units=256, activation='relu', kernel_initializer='he_uniform',\n",
        "                      bias_initializer='he_uniform', kernel_regularizer=regularizers.l2(0.0005))(class_branch)\n",
        "    gfn_units = BatchNormalization()(gfn_units)\n",
        "\n",
        "    color_branch = Add()([color_branch, Lambda(tile, arguments={'k': K.shape(color_branch)})(gfn_units)])\n",
        "    color_branch = color()(color_branch)\n",
        "\n",
        "    class_branch = clf()(class_branch)\n",
        "\n",
        "    model = Model(inputs=[color_input, class_input], outputs=[color_branch, class_branch], name='global_model')\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9v0zseHaR3U9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Generator Class"
      ]
    },
    {
      "metadata": {
        "id": "sAOyCrWbTJuq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, list_IDs, partition, labels, batch_size=28, n_channel=1, n_classes=719, shuffle=True, augment=False):\n",
        "        if augment:\n",
        "            self.list_IDs = list_IDs * 3\n",
        "        else:\n",
        "            self.list_IDs = list_IDs\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.n_channel = n_channel\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augment\n",
        "        self.partition = partition\n",
        "        self.prng = np.random.RandomState(42)\n",
        "        self.datagen = ImageDataGenerator(rotation_range=45, width_shift_range=0.15, height_shift_range=0.15, shear_range=0.15,\n",
        "                                          fill_mode='constant', cval=0, zoom_range=0.15, horizontal_flip=True)\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            self.prng.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "        return self.__data_generation(list_IDs_temp)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        X = np.empty((self.batch_size, 224, 224, self.n_channel))\n",
        "        Y = np.empty((self.batch_size, 224, 224, 2))\n",
        "        y = np.empty((self.batch_size,), dtype=int)\n",
        "\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            if not self.augment:\n",
        "                X[i] = np.expand_dims(\n",
        "                    (imread(os.path.join(os.path.join('data', self.partition), ID)) - 127.5) / 127.5, axis=-1)\n",
        "                Y[i] = (rgb2lab(imread(os.path.join(os.path.join('data', self.partition + '-target'), ID)))\n",
        "                        [:, :, 1:] + 128.0) / (255.0)\n",
        "                y[i] = self.labels[ID]\n",
        "            else:\n",
        "                seed = self.prng.randint(0, 1000000)\n",
        "                X[i] = (self.datagen.random_transform(np.expand_dims(\n",
        "                    imread(os.path.join(os.path.join('data', self.partition), ID)), axis=-1), seed=seed) - 127.5) / 127.5\n",
        "                Y[i] = (rgb2lab(self.datagen.random_transform(imread(os.path.join(os.path.join('data', self.partition + '-target'), ID)), seed=seed))\n",
        "                        [:, :, 1:] + 128.0) / (255.0)\n",
        "                y[i] = self.labels[ID]\n",
        "        return ([X, X], [Y, to_categorical(y, num_classes=self.n_classes)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Un3PccfGTpzt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save Callback Class"
      ]
    },
    {
      "metadata": {
        "id": "UdUK3eCrTxya",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SaveCallback(Callback):\n",
        "    def __init__(self, model):\n",
        "        self.model_to_save = model\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        fname='weights.h5'\n",
        "        self.model_to_save.save_weights(fname)\n",
        "        d = {}\n",
        "        if os.path.exists('epochs.json'):\n",
        "            d = json.load(open('epochs.json'))\n",
        "        d[epoch] = logs\n",
        "        json.dump(d, open('epochs.json', 'w'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N5aFAy7zT0nc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Method"
      ]
    },
    {
      "metadata": {
        "id": "GGjqj2VTT4I3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    labels = json.load(open(os.path.join('data', 'labels.json')))\n",
        "    partition = {'training': None, 'validation': None}\n",
        "    for x in partition.keys():\n",
        "        partition[x] = [f for f in os.listdir(os.path.join('data', x)) if os.path.isfile(\n",
        "            os.path.join(os.path.join('data', x), f))]\n",
        "        partition[x].sort()\n",
        "    print('Indices read.')\n",
        "\n",
        "    n_classes = len({labels[x] for x in labels})\n",
        "    l = {labels[x] for x in labels}\n",
        "    l = {x: i for i, x in enumerate(sorted(list(l)))}\n",
        "    labels = {x: l[labels[x]] for x in labels.keys()}\n",
        "    json.dump(l, open('mapping.json', 'w'))\n",
        "    print('Mappings written.')\n",
        "\n",
        "    training_generator = DataGenerator(partition['training'], 'training', labels, 64, 1, n_classes, True, True)\n",
        "    validation_generator = DataGenerator(partition['validation'], 'validation', labels, 64, 1, n_classes, True, True)\n",
        "\n",
        "    fmodel = model()\n",
        "    if os.path.exists('weights.h5'):\n",
        "        fmodel.load_weights('weights.h5')\n",
        "\n",
        "    initial_epoch = 0\n",
        "    if os.path.exists('epochs.json'):\n",
        "        initial_epoch = len(json.load(open('epochs.json')).keys())\n",
        "\n",
        "    cbk = SaveCallback(fmodel)\n",
        "    fmodel.compile(optimizer='adadelta', loss={\n",
        "        'color_model': 'mean_squared_error', 'clf_model': 'categorical_crossentropy'}, metrics={'color_model': 'accuracy', 'clf_model': 'accuracy'})\n",
        "    fmodel.fit_generator(generator=training_generator, epochs=45, verbose=1, callbacks=[\n",
        "        cbk], validation_data=validation_generator, use_multiprocessing=True, workers=4, initial_epoch=initial_epoch)\n",
        "    print('Training done.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oG1JquQyvwM3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "d5a4b000-2e72-4964-c715-2c0042ef6472"
      },
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indices read.\n",
            "Mappings written.\n",
            "Epoch 41/45\n",
            "466/841 [===============>..............] - ETA: 15:40 - loss: 5.2238 - color_model_loss: 0.0019 - clf_model_loss: 3.0715 - color_model_acc: 0.6464 - clf_model_acc: 0.4059"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "841/841 [==============================] - 2320s 3s/step - loss: 5.2130 - color_model_loss: 0.0019 - clf_model_loss: 3.0430 - color_model_acc: 0.6464 - clf_model_acc: 0.4071 - val_loss: 5.7599 - val_color_model_loss: 0.0019 - val_clf_model_loss: 3.5546 - val_color_model_acc: 0.7080 - val_clf_model_acc: 0.3560\n",
            "Epoch 42/45\n",
            " 72/841 [=>............................] - ETA: 31:03 - loss: 5.1337 - color_model_loss: 0.0018 - clf_model_loss: 2.9256 - color_model_acc: 0.6541 - clf_model_acc: 0.4223"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "659/841 [======================>.......] - ETA: 7:30 - loss: 5.1956 - color_model_loss: 0.0019 - clf_model_loss: 2.9613 - color_model_acc: 0.6493 - clf_model_acc: 0.4186"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "841/841 [==============================] - 2300s 3s/step - loss: 5.2100 - color_model_loss: 0.0019 - clf_model_loss: 2.9693 - color_model_acc: 0.6496 - clf_model_acc: 0.4166 - val_loss: 5.7018 - val_color_model_loss: 0.0019 - val_clf_model_loss: 3.4292 - val_color_model_acc: 0.5661 - val_clf_model_acc: 0.3613\n",
            "Epoch 43/45\n",
            "139/841 [===>..........................] - ETA: 29:19 - loss: 5.1735 - color_model_loss: 0.0019 - clf_model_loss: 2.8953 - color_model_acc: 0.6503 - clf_model_acc: 0.4258"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "726/841 [========================>.....] - ETA: 4:45 - loss: 5.2514 - color_model_loss: 0.0019 - clf_model_loss: 2.9476 - color_model_acc: 0.6502 - clf_model_acc: 0.4209"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "841/841 [==============================] - 2310s 3s/step - loss: 5.2607 - color_model_loss: 0.0019 - clf_model_loss: 2.9524 - color_model_acc: 0.6501 - clf_model_acc: 0.4195 - val_loss: 5.7770 - val_color_model_loss: 0.0019 - val_clf_model_loss: 3.4394 - val_color_model_acc: 0.6354 - val_clf_model_acc: 0.3549\n",
            "Epoch 44/45\n",
            "162/841 [====>.........................] - ETA: 28:27 - loss: 5.2153 - color_model_loss: 0.0018 - clf_model_loss: 2.8750 - color_model_acc: 0.6539 - clf_model_acc: 0.4268"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "750/841 [=========================>....] - ETA: 3:46 - loss: 5.2972 - color_model_loss: 0.0019 - clf_model_loss: 2.9394 - color_model_acc: 0.6437 - clf_model_acc: 0.4217"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "841/841 [==============================] - 2311s 3s/step - loss: 5.3022 - color_model_loss: 0.0019 - clf_model_loss: 2.9425 - color_model_acc: 0.6436 - clf_model_acc: 0.4214 - val_loss: 5.9124 - val_color_model_loss: 0.0022 - val_clf_model_loss: 3.5332 - val_color_model_acc: 0.6757 - val_clf_model_acc: 0.3475\n",
            "Epoch 45/45\n",
            " 46/841 [>.............................] - ETA: 34:15 - loss: 5.2445 - color_model_loss: 0.0018 - clf_model_loss: 2.8656 - color_model_acc: 0.6444 - clf_model_acc: 0.4399"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G1Y3nvQXbn2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "a9a54ddb-262c-4a5c-d608-1304c4fc5455"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('epochs.json')\n",
        "files.download('weights.h5')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7346584c886a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m   \u001b[0mstarted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: epochs.json"
          ]
        }
      ]
    }
  ]
}